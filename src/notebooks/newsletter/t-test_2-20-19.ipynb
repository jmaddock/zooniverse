{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import mailbox\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# compiled regex for getting date sent from email dump\n",
    "match = re.compile('Date: .*')\n",
    "\n",
    "# extract the initial send date from the message body\n",
    "def parse_date(message):\n",
    "    date_string = re.findall(match, message)[0].split(', ',1)[1]\n",
    "    date_time = datetime.strptime(date_string,'%b %d, %Y at %I:%M %p')\n",
    "    return date_time\n",
    "\n",
    "# create a new column of timedeltas between rows\n",
    "def create_timedelta(df):\n",
    "    df = df.sort_values('date')\n",
    "    df['timedelta'] = df['date'].subtract(df['date'].shift(1))\n",
    "    return df[1:-1]\n",
    "\n",
    "def create_email_df(mbox_path):\n",
    "    # load emails from file\n",
    "    mbox = mailbox.mbox(mbox_path)\n",
    "    \n",
    "    # iterate through email dump and extract all send dates\n",
    "    date_list = []\n",
    "\n",
    "    for m in mbox:\n",
    "        body = m.get_payload(0).as_string()\n",
    "        date = parse_date(body)\n",
    "        date_list.append(date)\n",
    "        \n",
    "    # create a dataframe with timedeltas\n",
    "    df = pd.DataFrame({'date':date_list})\n",
    "    df = create_timedelta(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjm668/dev/zooniverse/src/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (0,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# load all data\n",
    "email_df = create_email_df('/srv/zooniverse/raw_data/emails/zooniverse.mbox')\n",
    "classification_df = pd.read_csv('/srv/zooniverse/tables/all_classifications_table_02-18-19.csv')\n",
    "project_df = pd.read_csv('/srv/zooniverse/tables/all_projects_table_02-18-19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_weeks(x):\n",
    "    return x.isocalendar()[0]*52+x.isocalendar()[1]\n",
    "\n",
    "# only use \"official\" projects and classifications\n",
    "classification_df = classification_df.loc[classification_df['panoptes_api_official_project'] == 1]\n",
    "project_df = project_df.loc[(project_df['panoptes_api_official_project'] == 1)]\n",
    "\n",
    "# only include projects that also have classification data\n",
    "project_df = project_df.loc[((project_df['panoptes_api'] == 1) & (project_df['ouroboros_dump'] == 1)) | (project_df['panoptes_dump'] == 1) & (project_df['panoptes_api'] == 1)]\n",
    "\n",
    "# convert classification timestamp to datetime\n",
    "classification_df['created_at'] = pd.to_datetime(classification_df['created_at'])\n",
    "\n",
    "# create iso_week column for email and classification dfs\n",
    "email_df['iso_week'] = email_df['date'].apply(get_weeks)\n",
    "classification_df['iso_week'] = classification_df['created_at'].apply(get_weeks)\n",
    "\n",
    "# add project name to classification df\n",
    "classification_df = classification_df.merge(project_df[['panoptes_project_name','panoptes_project_id']],on='panoptes_project_id',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Run to only use Panoptes Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# only use panoptes classifications\n",
    "classification_df = classification_df.loc[classification_df['panoptes_dump'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Run to only use emails during classification window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove emails sent later than panoptes classification data\n",
    "email_df = email_df.loc[email_df['iso_week'] < classification_df['iso_week'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove emails from subsequent weeks\n",
    "email_df = email_df.loc[~email_df['iso_week'].isin(email_df['iso_week'].add(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ttest(classification_df, email_df, window=1):\n",
    "\n",
    "    # group classifications by project and iso_week\n",
    "    classifications_by_week = classification_df.groupby(['panoptes_project_id','iso_week'])['iso_week'].size()\n",
    "    # add 0s for missing weeks\n",
    "    classifications_by_week = classifications_by_week.reindex(pd.MultiIndex.from_product(classifications_by_week.index.levels, names=classifications_by_week.index.names),fill_value=0)\n",
    "    classifications_by_week = classifications_by_week.to_frame('classification_count').reset_index()\n",
    "    \n",
    "    # create dfs with start and end iso_weeks\n",
    "    start = email_df['iso_week'].subtract(window).to_frame('start')\n",
    "    end = email_df['iso_week'].add(window-1).to_frame('end')\n",
    "    windowed_classifications_by_week_start = classifications_by_week.loc[(classifications_by_week['iso_week'].isin(start['start']))]\n",
    "    windowed_classifications_by_week_end = classifications_by_week.loc[(classifications_by_week['iso_week'].isin(end['end']))]\n",
    "    \n",
    "    # merge start and end week classification counts into single df\n",
    "    windowed_classifications_by_week_end['iso_week'] = windowed_classifications_by_week_end['iso_week'].subtract(1)\n",
    "    windowed_classifications_by_week = windowed_classifications_by_week_start.merge(windowed_classifications_by_week_end,on=['panoptes_project_id','iso_week'])\n",
    "    \n",
    "    # only include weeks where there was at least one classification before or after the newsletter\n",
    "    windowed_classifications_by_week = windowed_classifications_by_week.loc[(windowed_classifications_by_week['classification_count_x'] > 0) | (windowed_classifications_by_week['classification_count_y'] > 0)]\n",
    "    \n",
    "    ttest = stats.ttest_ind(windowed_classifications_by_week['classification_count_x'].values,\n",
    "                            windowed_classifications_by_week['classification_count_y'].values,\n",
    "                            equal_var = False)\n",
    "    \n",
    "    print('statistic: {0}\\np value: {1})'.format(ttest.statistic,ttest.pvalue))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run T-Test\n",
    "perform a for the difference in means between classifications per project the week before the newsletter and the week of the newsletter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistic: -1.3321141370774052\n",
      "p value: 0.18337514041076183)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjm668/dev/zooniverse/src/venv/lib/python3.5/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "ttest(classification_df,email_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
